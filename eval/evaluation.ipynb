{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hazot/miniconda3/envs/nlg/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import transformers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import GPT2Tokenizer, AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredients_list(recipe):\n",
    "    '''\n",
    "    Gets the list of input ingredients from a raw recipe\n",
    "    '''\n",
    "    ingr_start_index = recipe.find(\"<INPUT_START>\")\n",
    "    ingr_end_index = recipe.find(\"<INPUT_END>\")\n",
    "\n",
    "    ingredients_sequence = \" \".join(recipe[ingr_start_index + len(\"<INPUT_START>\"):ingr_end_index].strip().split())  # Find the input ingredients list sequence\n",
    "    ingredients_list = ingredients_sequence.split(\"<NEXT_INPUT>\")  # split the ingredients when the next input token is reached\n",
    "    return [x.strip() for x in ingredients_list]  # strip whitespaces before and after ingredients\n",
    "\n",
    "\n",
    "def print_raw_recipe(full_raw_recipe):\n",
    "    '''\n",
    "    Print a raw recipe (containing the special tokens) to be easier to read\n",
    "    '''\n",
    "    markdown = re.sub(\"<RECIPE_(START|END)>\", \"\", full_raw_recipe)\n",
    "    recipe_n_title = markdown.split(\"<TITLE_START>\")\n",
    "    title = \"# \" + recipe_n_title[1].replace(\"<TITLE_END>\", \"\") + \" #\\n\"\n",
    "    markdown = recipe_n_title[0].replace(\"<INPUT_START>\", \"## Input ingredients ##\\n`\").replace(\"<INPUT_END>\", \"`\\n\")\n",
    "    markdown = markdown.replace(\"<NEXT_INPUT>\", \"`\\n`\").replace(\"<INGR_START>\",\"## Ingredients ##\\n* \").replace(\"<NEXT_INGR>\",\"\\n* \").replace(\"<INGR_END>\", \"\\n\")\n",
    "    markdown = markdown.replace(\"<INSTR_START>\", \"## Instructions ##\\n1) \")\n",
    "\n",
    "    # Count each instruction\n",
    "    count = 2\n",
    "    while markdown.find(\"<NEXT_INSTR>\") != -1:\n",
    "        markdown = markdown.replace(\"<NEXT_INSTR>\", f\"\\n{count}) \", 1)\n",
    "        count += 1\n",
    "\n",
    "    markdown = markdown.replace(\"<INSTR_END>\", \"\\n\")\n",
    "    markdown = re.sub(\"$ +#\", \"#\", markdown)\n",
    "    markdown = re.sub(\"( +`|` +)\", \"`\", markdown)\n",
    "    print('\\n' + title + markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hazot/code/recipe-generation-project/results/2023-07-20_12-25-38/sample_gpt2.txt\n",
      "/home/hazot/code/recipe-generation-project/results/2023-07-20_12-25-38/finetuned_gpt2.txt\n"
     ]
    }
   ],
   "source": [
    "local_path = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "sample_path = local_path + \"/results/2023-07-20_12-25-38/sample_gpt2.txt\"\n",
    "finetuned_path = local_path + \"/results/2023-07-20_12-25-38/finetuned_gpt2.txt\"\n",
    "print(sample_path)\n",
    "print(finetuned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir=\"data\"\n",
    "\n",
    "data = {\n",
    "    \"sample\": [],\n",
    "    \"finetuned\": [],\n",
    "    \"vanilla\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    data[\"sample\"] = [content[i * 2].replace('\\n','') for i in range(len(content) // 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(finetuned_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    data[\"finetuned\"] = [content[i * 2].replace('\\n','') for i in range(len(content) // 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(data['sample']))\n",
    "print(len(data['finetuned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#  Pina Colada Cookie Cookies With Coconut Glaze   #\n",
      " ## Input ingredients ##\n",
      "`sweet rice flour`\n",
      "`coconut`\n",
      "`coconut milk`\n",
      "`cooking oil`\n",
      "`Coating`\n",
      "`brown sugar`\n",
      "`coconut milk`\n",
      "`coconut milk`\n",
      "`powdered sugar`\n",
      "`flour`\n",
      "`ground cinnamon`\n",
      "`baking powder`\n",
      "`baking soda`\n",
      "`salt`\n",
      "`vegetable shortening`\n",
      "`coconut`\n",
      "`sugar`\n",
      "`water`\n",
      "`light corn syrup`\n",
      "`coconut milk`\n",
      "`egg whites`\n",
      " ## Ingredients ##\n",
      "*  Chocolate Glaze: \n",
      "*  1 cup sweet rice flour \n",
      "*  1 cup coconut flakes (recommended: Rollit) \n",
      "*  3/4 cup coconut milk, plus \n",
      "*  1 tablespoon cooking oil, plus \n",
      "*  Coating: \n",
      "*  1/2 cup packed light brown sugar \n",
      "*  1/2 cup coconut milk \n",
      "*  1/2 cup coconut milk \n",
      "*  1 1/4 cups powdered sugar \n",
      "*  1 cup all-purpose flour \n",
      "*  1 teaspoon ground cinnamon \n",
      "*  1 teaspoon baking powder \n",
      "*  1 teaspoon baking soda \n",
      "*  1/2 teaspoon salt \n",
      "*  3/4 cup vegetable shortening \n",
      "*  1 cup sweetened flaked coconut \n",
      "*  1/2 cup sugar \n",
      "*  1/4 cup water \n",
      "*  3 tablespoons light corn syrup \n",
      "*  2 tablespoons coconut milk \n",
      "*  2 large egg whites, beaten \n",
      " ## Instructions ##\n",
      "1)  To make the Chocolate Glaze: In a bowl, combine sweet rice flour, coconut flakes and coconut milk and stir to combine. Set aside. \n",
      "2)  To make the coating: In a bowl, combine brown sugar, coconut milk, 1/2 cup coconut milk, 1/2 cup powdered sugar, all-purpose flour, cinnamon, baking powder, baking soda and salt. In a separate bowl, combine vegetable shortening, coconut and 1/2 cup coconut milk and beat until fluffy. Add egg whites and beat until combined. Add flour mixture, beating until smooth. \n",
      "3)  Form dough into 1 inch balls, then flatten with a rolling pin. Coat with chocolate glaze. \n",
      "4)  Place 2 inches apart on ungreased cookie sheets. Bake at 350Â° for 6-8 minutes or until edges are lightly browned. Transfer to a wire rack and let cool on sheets for 2 minutes before removing to a wire rack to cool completely. \n",
      "5)  To make the confectioners' sugar: In a bowl, combine sugar, water, corn syrup, coconut milk and egg whites and beat until smooth. Spread over cooled cookies, then chill until set, about 2 hours. Store in an airtight container. \n",
      "6)  Tips: Nutritional analysis is per 1 1/2-ounce cookie. \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print_raw_recipe(data['finetuned'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(local_path + '/checkpoints/gpt2/checkpoint-gpt2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = [tokenizer.encode(recipe) for recipe in data['sample']]\n",
    "finetuned_tensor = [tokenizer.encode(recipe) for recipe in data['finetuned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = 0\n",
    "for k, rec1 in enumerate(sample_tensor):\n",
    "    best = 0\n",
    "    for i in range(0,10):\n",
    "        rec2 = finetuned_tensor[k*10 + i]\n",
    "        \n",
    "        # pad\n",
    "        pad_len = np.abs(len(rec1) - len(rec2))\n",
    "        if len(rec1) < len(rec2):\n",
    "            rec1.extend([0]*pad_len)\n",
    "        else:\n",
    "            rec2.extend([0]*pad_len)\n",
    "        \n",
    "        cos = cosine_similarity([rec1], [rec2])\n",
    "        best = max(best, cos)\n",
    "    avg += best\n",
    "\n",
    "avg = avg/len(sample_tensor)\n",
    "print(\"avg: \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Language check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "#tool.disable_spellchecking()\n",
    "results = tool.check(data[\"finetuned\"][0])\n",
    "results_filtered = [result for result in results if result.ruleId!='WHITESPACE_RULE' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "#tool.disable_spellchecking()\n",
    "\n",
    "avg = 0\n",
    "dataset = \"finetuned\"\n",
    "\n",
    "for rec in tqdm(data[dataset], desc=\"Iteration\", disable=False, position=0, leave=True):\n",
    "    results = tool.check(rec)\n",
    "    results_filtered = [result for result in results if result.ruleId!='WHITESPACE_RULE' ]\n",
    "    avg += len(results_filtered)\n",
    "\n",
    "print(avg / len(data[dataset]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Readibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* textstat.smog_index(test_data)\n",
    "* textstat.flesch_kincaid_grade(test_data)\n",
    "* textstat.coleman_liau_index(test_data)\n",
    "* textstat.automated_readability_index(test_data)\n",
    "* textstat.dale_chall_readability_score(test_data)\n",
    "* textstat.difficult_words(test_data)\n",
    "* textstat.linsear_write_formula(test_data)\n",
    "* textstat.gunning_fog(test_data)\n",
    "* textstat.text_standard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import textstat\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"finetuned\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.flesch_reading_ease(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"sample\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.smog_index(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"finetuned\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.gunning_fog(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"sample\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.dale_chall_readability_score(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.translate.bleu_score as bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import nltk.translate.gleu_score as gleu\n",
    "import nltk.translate.meteor_score as meteor\n",
    "from jiwer import wer, mer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer_count(hyp, ref, print_matrix=False):\n",
    "    N = len(hyp)\n",
    "    M = len(ref)\n",
    "    L = np.zeros((N,M))\n",
    "    for i in range(0, N):\n",
    "        for j in range(0, M):\n",
    "            if min(i,j) == 0:\n",
    "                L[i,j] = max(i,j)\n",
    "            else:\n",
    "                deletion = L[i-1,j] + 1\n",
    "                insertion = L[i,j-1] + 1\n",
    "                sub = 1 if hyp[i] != ref[j] else 0\n",
    "                substitution = L[i-1,j-1] + sub\n",
    "                L[i,j] = min(deletion, min(insertion, substitution))\n",
    "    return int(L[N-1, M-1])\n",
    "\n",
    "def bleu_score(recipe, refer):\n",
    "    hyp = recipe\n",
    "    refs = refer\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    score_ref_a = bleu.sentence_bleu(refs, hyp, smoothing_function=smoothie)\n",
    "    return score_ref_a\n",
    "\n",
    "def gleu_score(recipe, refer):\n",
    "    hyp = recipe\n",
    "    refs = refer\n",
    "    score_ref_a = gleu.sentence_gleu(refs, hyp)\n",
    "    return score_ref_a\n",
    "\n",
    "def wer_score(recipe, refer):\n",
    "    hyp = recipe\n",
    "    refs = refer\n",
    "\n",
    "    mn = 99999\n",
    "    for ref in refs:\n",
    "        b = wer(ref, hyp)\n",
    "        mn = min(mn, b)\n",
    "       \n",
    "    return mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for k, rec1 in enumerate(tqdm(data[\"sample\"])):\n",
    "    rec2 = data[\"finetuned\"][k*10: k*10 + 10]\n",
    "    res = bleu_score(rec1, rec2)\n",
    "    ret.append(res)\n",
    "\n",
    "np.mean(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for k, rec1 in enumerate(tqdm(data[\"sample\"])):\n",
    "    rec2 = data[\"finetuned\"][k*10: k*10 + 10]\n",
    "    res = gleu_score(rec1, rec2)\n",
    "    ret.append(res)\n",
    "\n",
    "np.mean(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for k, rec1 in enumerate(tqdm(data[\"sample\"])):\n",
    "    rec2 = data[\"finetuned\"][k*10: k*10 + 10]\n",
    "    res = wer_score(rec1, rec2)\n",
    "    ret.append(res)\n",
    "\n",
    "np.mean(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingredients evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if all the ingredients from the input list are used inside the generated instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instructions(recipe):\n",
    "    '''\n",
    "    Gets the string sequence of instructions from a raw recipe\n",
    "    '''\n",
    "    instr_start_index = recipe.find(\"<INSTR_START>\")\n",
    "    instr_end_index = recipe.find(\"<INSTR_END>\")\n",
    "\n",
    "    instruction_sequence = \" \".join(recipe[instr_start_index + len(\"<INSTR_START>\"):instr_end_index].strip().split())  # Find the input ingredients list sequence\n",
    "    instructions = instruction_sequence.split(\"<NEXT_INSTR>\")  # split the ingredients when the next input token is reached\n",
    "    instructions = [x.strip() for x in instructions]  # strip whitespaces before and after ingredients\n",
    "    return \" \".join(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredient_coverage_in_instructions(recipes):\n",
    "    results = []\n",
    "    for recipe in recipes:\n",
    "        ingredients = get_ingredients_list(recipe)\n",
    "        instructions = get_instructions(recipe).lower()\n",
    "\n",
    "        ingredients = list(dict.fromkeys(ingredients))  # remove duplicate ingredient to remove bias\n",
    "\n",
    "        count = sum([1 if re.search(ingredient.lower(), instructions) else 0 for ingredient in ingredients])\n",
    "    \n",
    "        results.append(count / len(ingredients))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_ingredient_coverage_in_instructions(data['finetuned'])\n",
    "print(np.mean(res))\n",
    "print(np.argmin(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<RECIPE_START> <INPUT_START> margarine <NEXT_INPUT>  cooking oats <NEXT_INPUT>  sugar <NEXT_INPUT>  cinnamon <NEXT_INPUT>  applesauce <NEXT_INPUT>  whipped cream<INPUT_END> <INGR_START> 1 stick margarine <NEXT_INGR> 2 c. quick cooking oats <NEXT_INGR> 1/2 c. sugar <NEXT_INGR> 1/2 tsp. cinnamon <NEXT_INGR> 1 (12 oz.) can applesauce <NEXT_INGR> 1 c. whipped cream <INGR_END> <INSTR_START> Mix first 4 ingredients; set aside. <NEXT_INSTR> Combine apple sauce and 1 cup whipped cream. <NEXT_INSTR> Combine all ingredients and chill. <INSTR_END> <TITLE_START> Mountain Oatmeal Pie <TITLE_END> <RECIPE_END>'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe = data['finetuned'][-5]\n",
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['margarine',\n",
       " 'cooking oats',\n",
       " 'sugar',\n",
       " 'cinnamon',\n",
       " 'applesauce',\n",
       " 'whipped cream']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ingredients_list(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#  Mountain Oatmeal Pie   #\n",
      " ## Input ingredients ##\n",
      "`margarine`\n",
      "`cooking oats`\n",
      "`sugar`\n",
      "`cinnamon`\n",
      "`applesauce`\n",
      "`whipped cream`\n",
      " ## Ingredients ##\n",
      "*  1 stick margarine \n",
      "*  2 c. quick cooking oats \n",
      "*  1/2 c. sugar \n",
      "*  1/2 tsp. cinnamon \n",
      "*  1 (12 oz.) can applesauce \n",
      "*  1 c. whipped cream \n",
      " ## Instructions ##\n",
      "1)  Mix first 4 ingredients; set aside. \n",
      "2)  Combine apple sauce and 1 cup whipped cream. \n",
      "3)  Combine all ingredients and chill. \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print_raw_recipe(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['margarine',\n",
       " 'cooking oats',\n",
       " 'sugar',\n",
       " 'cinnamon',\n",
       " 'applesauce',\n",
       " 'whipped cream']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients = get_ingredients_list(recipe)\n",
    "ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mix first 4 ingredients; set aside. Combine apple sauce and 1 cup whipped cream. Combine all ingredients and chill.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = get_instructions(recipe)\n",
    "instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(66, 79), match='whipped cream'>\n"
     ]
    }
   ],
   "source": [
    "ingredients_cleared = list(dict.fromkeys(ingredients))  # remove duplicate ingredient to remove bias\n",
    "for ingr in ingredients_cleared:\n",
    "    x = re.search(ingr, instructions)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if all the ingredients from the ingredients list are used inside the generated instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if there are any duplicates ingredients in the input list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if there are any duplicates ingredients in the ingredient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if all the ingredients found in the generated instructions are mentioned in the input list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if all the ingredients found in the generated instructions are mentioned in the ingredients list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlg (py3.9-cu11.7)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
