{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b89a7b-b95b-42c2-8971-a631dd467ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hazot/miniconda3/envs/nlg/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import transformers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import GPT2Tokenizer, AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bff475-9680-42d6-9e71-0e97b6651c72",
   "metadata": {},
   "source": [
    "## Defining some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e9f4d-5cab-441c-a6c0-9c073d2630f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_raw_recipe(full_raw_recipe):\n",
    "    '''\n",
    "    Print a raw recipe (containing the special tokens) to be easier to read\n",
    "    '''\n",
    "    markdown = re.sub(\"<RECIPE_(START|END)>\", \"\", full_raw_recipe)\n",
    "    recipe_n_title = markdown.split(\"<TITLE_START>\")\n",
    "    title = \"# \" + recipe_n_title[1].replace(\"<TITLE_END>\", \"\") + \" #\\n\"\n",
    "    markdown = recipe_n_title[0].replace(\"<INPUT_START>\", \"## Input ingredients ##\\n`\").replace(\"<INPUT_END>\", \"`\\n\")\n",
    "    markdown = markdown.replace(\"<NEXT_INPUT>\", \"`\\n`\").replace(\"<INGR_START>\",\"## Ingredients ##\\n* \").replace(\"<NEXT_INGR>\",\"\\n* \").replace(\"<INGR_END>\", \"\\n\")\n",
    "    markdown = markdown.replace(\"<INSTR_START>\", \"## Instructions ##\\n1) \")\n",
    "\n",
    "    # Count each instruction\n",
    "    count = 2\n",
    "    while markdown.find(\"<NEXT_INSTR>\") != -1:\n",
    "        markdown = markdown.replace(\"<NEXT_INSTR>\", f\"\\n{count}) \", 1)\n",
    "        count += 1\n",
    "\n",
    "    markdown = markdown.replace(\"<INSTR_END>\", \"\\n\")\n",
    "    markdown = re.sub(\"$ +#\", \"#\", markdown)\n",
    "    markdown = re.sub(\"( +`|` +)\", \"`\", markdown)\n",
    "    print('\\n' + title + markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6aa4a-523c-4c8e-adc2-5841f5682236",
   "metadata": {},
   "source": [
    "## Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8723d2d-cecc-45f4-b147-40585271ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "sample_path = local_path + \"/results/2023-07-25_16-14-49/sample_gpt2.txt\"\n",
    "finetuned_path = local_path + \"/results/2023-07-25_16-14-49/finetuned_gpt2.txt\"\n",
    "print(sample_path)\n",
    "print(finetuned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f0a4d3-7b83-4c70-9558-eecefa349d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"data\"\n",
    "\n",
    "data = {\n",
    "    \"sample\": [],\n",
    "    \"finetuned\": [],\n",
    "    \"vanilla\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e316c57-4f95-49d6-b903-98d7358c6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    data[\"sample\"] = [content[i * 2].replace('\\n','') for i in range(len(content) // 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6004687f-6428-4683-87d7-3fc81d88b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(finetuned_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    data[\"finetuned\"] = [content[i * 2].replace('\\n','') for i in range(len(content) // 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8870b4f7-d7dc-4c0a-8a05-05b086610dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data['sample']))\n",
    "print(len(data['finetuned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c41e7d2-24d3-4b03-bc0c-6a6f5f3a2129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0192912-04ea-4205-bd1c-1a07f081c099",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb2a90-9896-453e-87df-8b3cf24ab385",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(local_path + '/checkpoints/gpt2/checkpoint-gpt2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25eab7b-95a8-4bd1-b051-de84cf1ee6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = [tokenizer.encode(recipe) for recipe in data['sample']]\n",
    "finetuned_tensor = [tokenizer.encode(recipe) for recipe in data['finetuned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ad16b-a8f8-4e05-ad1c-69a5a1b28562",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = 0\n",
    "for k, rec1 in enumerate(sample_tensor):\n",
    "    best = 0\n",
    "    for i in range(0,10):\n",
    "        rec2 = finetuned_tensor[k*10 + i]\n",
    "        \n",
    "        # pad\n",
    "        pad_len = np.abs(len(rec1) - len(rec2))\n",
    "        if len(rec1) < len(rec2):\n",
    "            rec1.extend([0]*pad_len)\n",
    "        else:\n",
    "            rec2.extend([0]*pad_len)\n",
    "        \n",
    "        cos = cosine_similarity([rec1], [rec2])\n",
    "        best = max(best, cos)\n",
    "    avg += best\n",
    "\n",
    "avg = avg/len(sample_tensor)\n",
    "print(\"avg: \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9240a0-f4ef-472f-9a5c-4dddeaa3be93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Language check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cde529-0a5a-41e7-ab11-3a17ff9bedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "#tool.disable_spellchecking()\n",
    "results = tool.check(data[\"finetuned\"][0])\n",
    "results_filtered = [result for result in results if result.ruleId!='WHITESPACE_RULE' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb2782-d988-4237-9cf0-31443531b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "#tool.disable_spellchecking()\n",
    "\n",
    "avg = 0\n",
    "dataset = \"finetuned\"\n",
    "\n",
    "for rec in tqdm(data[dataset], desc=\"Iteration\", disable=False, position=0, leave=True):\n",
    "    results = tool.check(rec)\n",
    "    results_filtered = [result for result in results if result.ruleId!='WHITESPACE_RULE' ]\n",
    "    avg += len(results_filtered)\n",
    "\n",
    "print(avg / len(data[dataset]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbffc0c-5712-44f4-bf68-c88cc25be4ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Readibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e5c60-f9b9-448f-9271-8dac6d2a9c54",
   "metadata": {},
   "source": [
    "* textstat.smog_index(test_data)\n",
    "* textstat.flesch_kincaid_grade(test_data)\n",
    "* textstat.coleman_liau_index(test_data)\n",
    "* textstat.automated_readability_index(test_data)\n",
    "* textstat.dale_chall_readability_score(test_data)\n",
    "* textstat.difficult_words(test_data)\n",
    "* textstat.linsear_write_formula(test_data)\n",
    "* textstat.gunning_fog(test_data)\n",
    "* textstat.text_standard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb58b01-6f2f-4399-8c80-318ac20d9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import textstat\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a337f6cd-ece0-41b1-9273-dc5c3a6e79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"finetuned\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.flesch_reading_ease(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c184800-6adb-41e0-a13c-b510e0b43243",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"sample\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.smog_index(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507eb934-d954-49b5-b3ea-70a687819660",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"finetuned\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.gunning_fog(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a6aee-d4b0-4edc-a78c-dfc2b69351ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"sample\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.dale_chall_readability_score(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4450140-2de7-4cc2-b8b3-2d4b21a3ad56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3712da7-24bb-48b3-b0d8-db7e109e2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.translate.bleu_score as bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import nltk.translate.gleu_score as gleu\n",
    "import nltk.translate.meteor_score as meteor\n",
    "from jiwer import wer, mer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609cacbb-3d7f-41c9-a865-641a80f3fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer_count(hyp, ref, print_matrix=False):\n",
    "    N = len(hyp)\n",
    "    M = len(ref)\n",
    "    L = np.zeros((N,M))\n",
    "    for i in range(0, N):\n",
    "        for j in range(0, M):\n",
    "            if min(i,j) == 0:\n",
    "                L[i,j] = max(i,j)\n",
    "            else:\n",
    "                deletion = L[i-1,j] + 1\n",
    "                insertion = L[i,j-1] + 1\n",
    "                sub = 1 if hyp[i] != ref[j] else 0\n",
    "                substitution = L[i-1,j-1] + sub\n",
    "                L[i,j] = min(deletion, min(insertion, substitution))\n",
    "    return int(L[N-1, M-1])\n",
    "\n",
    "def bleu_score(recipe, refer):\n",
    "    hyp = recipe\n",
    "    refs = refer\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    score_ref_a = bleu.sentence_bleu(refs, hyp, smoothing_function=smoothie)\n",
    "    return score_ref_a\n",
    "\n",
    "def gleu_score(recipe, refer):\n",
    "    hyp = recipe\n",
    "    refs = refer\n",
    "    score_ref_a = gleu.sentence_gleu(refs, hyp)\n",
    "    return score_ref_a\n",
    "\n",
    "def wer_score(recipe, refer):\n",
    "    hyp = recipe\n",
    "    refs = refer\n",
    "\n",
    "    mn = 99999\n",
    "    for ref in refs:\n",
    "        b = wer(ref, hyp)\n",
    "        mn = min(mn, b)\n",
    "       \n",
    "    return mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef899d-c1d0-486e-9cc0-fb48b405098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for k, rec1 in enumerate(tqdm(data[\"sample\"])):\n",
    "    rec2 = data[\"finetuned\"][k*10: k*10 + 10]\n",
    "    res = bleu_score(rec1, rec2)\n",
    "    ret.append(res)\n",
    "\n",
    "np.mean(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc71e3b-de06-47f7-a142-a5a38b09594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for k, rec1 in enumerate(tqdm(data[\"sample\"])):\n",
    "    rec2 = data[\"finetuned\"][k*10: k*10 + 10]\n",
    "    res = gleu_score(rec1, rec2)\n",
    "    ret.append(res)\n",
    "\n",
    "np.mean(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606a8b1-a040-44ee-95d6-7d06e732eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for k, rec1 in enumerate(tqdm(data[\"sample\"])):\n",
    "    rec2 = data[\"finetuned\"][k*10: k*10 + 10]\n",
    "    res = wer_score(rec1, rec2)\n",
    "    ret.append(res)\n",
    "\n",
    "np.mean(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a25655-4954-4499-8a83-d2de7effc319",
   "metadata": {},
   "source": [
    "# Ingredients evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbafa6a2-a282-4c11-9567-20b40b0192f1",
   "metadata": {},
   "source": [
    "### Test if all the ingredients from the input list are used inside the generated instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f1ba8-44ee-44fa-a188-2b3173c5fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_ingredients_list(recipe):\n",
    "    '''\n",
    "    Gets the list of input ingredients from a raw recipe\n",
    "    '''\n",
    "    ingr_start_index = recipe.find(\"<INPUT_START>\")\n",
    "    ingr_end_index = recipe.find(\"<INPUT_END>\")\n",
    "\n",
    "    ingredients_sequence = \" \".join(recipe[ingr_start_index + len(\"<INPUT_START>\"):ingr_end_index].strip().split())  # Find the input ingredients list sequence\n",
    "    ingredients_list = ingredients_sequence.split(\"<NEXT_INPUT>\")  # split the ingredients when the next input token is reached\n",
    "    return [x.strip() for x in ingredients_list]  # strip whitespaces before and after ingredients\n",
    "\n",
    "\n",
    "def get_instructions(recipe):\n",
    "    '''\n",
    "    Gets the string sequence of instructions from a raw recipe\n",
    "    '''\n",
    "    instr_start_index = recipe.find(\"<INSTR_START>\")\n",
    "    instr_end_index = recipe.find(\"<INSTR_END>\")\n",
    "\n",
    "    instruction_sequence = \" \".join(recipe[instr_start_index + len(\"<INSTR_START>\"):instr_end_index].strip().split())  # Find the input ingredients list sequence\n",
    "    instructions = instruction_sequence.split(\"<NEXT_INSTR>\")  # split the ingredients when the next input token is reached\n",
    "    instructions = [x.strip() for x in instructions]  # strip whitespaces before and after ingredients\n",
    "    return \" \".join(instructions)\n",
    "\n",
    "\n",
    "def input_ingredients_coverage_in_instructions(recipe):\n",
    "    '''\n",
    "    Returns the percentage of the number of ingredients from the input list that are actually present in the instructions for one recipe.\n",
    "    '''\n",
    "    ingredients = get_input_ingredients_list(recipe)\n",
    "    number_of_ingredients = len(ingredients)  # keeps the number of ingredients before removing duplicates\n",
    "    instructions = get_instructions(recipe).lower()\n",
    "\n",
    "    ingredients = list(dict.fromkeys(ingredients))  # remove duplicate ingredients to reduce bias\n",
    "    nb_ingr_found = sum([1 if ingredient.lower() in instructions else 0 for ingredient in ingredients])  # Gets the number of ingredients found in the instructions\n",
    "\n",
    "    return nb_ingr_found/number_of_ingredients\n",
    "\n",
    "\n",
    "def evaluate_recipes_input_ingredients_coverage_in_instructions(recipes):\n",
    "    '''\n",
    "    Evaluation on all the generated recipes (finetuned) for the coverage of the input list in the instructions.\n",
    "    Returns a list of percentage for the number of ingredients from the input list that are actually present in the instructions.\n",
    "    '''\n",
    "    results = []\n",
    "    for recipe in recipes:\n",
    "        results.append(input_ingredients_coverage_in_instructions(recipe))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09107d79-c8d6-4541-af9c-e967a719fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_recipes_input_ingredients_coverage_in_instructions(data['finetuned'])\n",
    "print('Average percentage of input ingredients covered:', np.mean(res))\n",
    "nb_of_zeros = sum([1 if x == 0.0 else 0 for x in res])\n",
    "print('Number of 0% coverage of input ingredients:', nb_of_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac938f5f-fc5e-410a-91a1-49ebe78c8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking on the samples to see how many zeros there are, therfore checking how many \"mix, combine, there are still in the training data\".\n",
    "res = evaluate_recipes_input_ingredients_coverage_in_instructions(data['sample'])\n",
    "print('Average percentage of input ingredients covered:', np.mean(res))\n",
    "nb_of_zeros = sum([1 if x == 0.0 else 0 for x in res])\n",
    "print('Number of 0% coverage of input ingredients:', nb_of_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ede456-accc-4870-a010-4c73f8753d99",
   "metadata": {},
   "source": [
    "### Test if all the ingredients from the input list are in the ingredient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a71a2-8335-431b-97fe-2d72bc683e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listed_ingredients_list(recipe):\n",
    "    '''\n",
    "    Gets the string sequence of listed ingredients (list with quantities) from a raw recipe\n",
    "    '''\n",
    "    ingr_start_index = recipe.find(\"<INGR_START>\")\n",
    "    ingr_end_index = recipe.find(\"<INGR_END>\")\n",
    "\n",
    "    ingredients_sequence = \" \".join(recipe[ingr_start_index + len(\"<INGR_START>\"):ingr_end_index].strip().split())  # Find the input ingredients list sequence\n",
    "    ingredients_list = ingredients_sequence.split(\"<NEXT_INGR>\")  # split the ingredients when the next input token is reached\n",
    "    ingredients_list = [x.strip() for x in ingredients_list]  # strip whitespaces before and after ingredients\n",
    "    return \" \".join(ingredients_list)\n",
    "\n",
    "\n",
    "def input_ingredients_coverage_in_listed_ingredients(recipe):\n",
    "    '''\n",
    "    Returns the percentage of the number of ingredients from the input list that are actually present in the listed ingredients (list with quantities) for one recipe.\n",
    "    '''\n",
    "    input_ingredients = get_input_ingredients_list(recipe)  # Gets input ingredients (without quantities)\n",
    "    number_of_ingredients = len(input_ingredients)  # keeps the number of ingredients before removing duplicates\n",
    "    \n",
    "    listed_ingredients = get_listed_ingredients_list(recipe).lower()  # Gets listed ingredients (the one with quanities)\n",
    "\n",
    "    ingredients = list(dict.fromkeys(input_ingredients))  # remove duplicate ingredients to reduce bias\n",
    "    nb_ingredients_found = sum([1 if input_ingredient.lower() in listed_ingredients else 0 for input_ingredient in input_ingredients])  # Gets the number of ingredients found in the listed ingredients\n",
    "    return nb_ingredients_found / number_of_ingredients\n",
    "\n",
    "\n",
    "def evaluate_recipes_input_ingredients_coverage_in_listed_ingredients(recipes):\n",
    "    '''\n",
    "    Evaluation on all the generated recipes (finetuned) for the coverage of the input list in the listed ingredients (list with quantities).\n",
    "    Returns a list of percentage for the number of ingredients from the input list that are actually present in the listed ingredients.\n",
    "    '''\n",
    "    results = []\n",
    "    for recipe in recipes:\n",
    "        results.append(input_ingredients_coverage_in_listed_ingredients(recipe))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959011f4-c6e9-4a4b-a0cd-f35142baace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_recipes_input_ingredients_coverage_in_listed_ingredients(data['finetuned'])\n",
    "print('Average percentage of input ingredients covered:', np.mean(res))\n",
    "indx_where_not_one = [i for i, x in enumerate(res) if x != 1.0]\n",
    "print('Number of non-100% coverage of input ingredients:', len(indx_where_not_one))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlg (py3.9-cu11.7)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
