{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hazot/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import transformers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import GPT2Tokenizer, AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_raw_recipe(full_raw_recipe):\n",
    "    '''\n",
    "    Print a raw recipe (containing the special tokens) to be easier to read\n",
    "    '''\n",
    "    markdown = re.sub(\"<RECIPE_(START|END)>\", \"\", full_raw_recipe)\n",
    "    recipe_n_title = markdown.split(\"<TITLE_START>\")\n",
    "    title = \"# \" + recipe_n_title[1].replace(\"<TITLE_END>\", \"\") + \" #\\n\"\n",
    "    markdown = recipe_n_title[0].replace(\"<INPUT_START>\", \"## Input ingredients ##\\n`\").replace(\"<INPUT_END>\", \"`\\n\")\n",
    "    markdown = markdown.replace(\"<NEXT_INPUT>\", \"`\\n`\").replace(\"<INGR_START>\",\"## Ingredients ##\\n* \").replace(\"<NEXT_INGR>\",\"\\n* \").replace(\"<INGR_END>\", \"\\n\")\n",
    "    markdown = markdown.replace(\"<INSTR_START>\", \"## Instructions ##\\n1) \")\n",
    "\n",
    "    # Count each instruction\n",
    "    count = 2\n",
    "    while markdown.find(\"<NEXT_INSTR>\") != -1:\n",
    "        markdown = markdown.replace(\"<NEXT_INSTR>\", f\"\\n{count}) \", 1)\n",
    "        count += 1\n",
    "\n",
    "    markdown = markdown.replace(\"<INSTR_END>\", \"\\n\")\n",
    "    markdown = re.sub(\"$ +#\", \"#\", markdown)\n",
    "    markdown = re.sub(\"( +`|` +)\", \"`\", markdown)\n",
    "    print('\\n' + title + markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hazot/code/recipe-generation-project/results/2023-07-25_16-14-49/sample_gpt2.txt\n",
      "/home/hazot/code/recipe-generation-project/results/2023-07-25_16-14-49/finetuned_gpt2.txt\n"
     ]
    }
   ],
   "source": [
    "local_path = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "sample_path = local_path + \"/results/2023-07-25_16-14-49/sample_gpt2.txt\"\n",
    "finetuned_path = local_path + \"/results/2023-07-25_16-14-49/finetuned_gpt2.txt\"\n",
    "print(sample_path)\n",
    "print(finetuned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir=\"data\"\n",
    "\n",
    "data = {\n",
    "    \"sample\": [],\n",
    "    \"finetuned\": [],\n",
    "    \"vanilla\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    data[\"sample\"] = [content[i * 2].replace('\\n','') for i in range(len(content) // 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(finetuned_path, 'r') as f:\n",
    "    content = f.readlines()\n",
    "    data[\"finetuned\"] = [content[i * 2].replace('\\n','') for i in range(len(content) // 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(data['sample']))\n",
    "print(len(data['finetuned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#  Snickerdoodles   #\n",
      " ## Input ingredients ##\n",
      "`Mix`\n",
      "`baking soda`\n",
      "`cream of tartar`\n",
      "`egg`\n",
      "`cinnamon`\n",
      " ## Ingredients ##\n",
      "*  2 1/2 c. Basic Cookie Mix \n",
      "*  1/4 tsp. baking soda \n",
      "*  1 tsp. cream of tartar \n",
      "*  1 egg \n",
      "*  2 Tbsp./1 tsp. cinnamon (to roll in) \n",
      " ## Instructions ##\n",
      "1)  Heat oven to 400Â°. \n",
      "2)  Mix well and roll into balls. \n",
      "3)  Roll in cinnamon and sugar mixture. \n",
      "4)  Flatten slightly. \n",
      "5)  Bake 8 to 10 minutes. \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print_raw_recipe(data['sample'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(local_path + '/checkpoints/gpt2/checkpoint-gpt2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = [tokenizer.encode(recipe) for recipe in data['sample']]\n",
    "finetuned_tensor = [tokenizer.encode(recipe) for recipe in data['finetuned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = 0\n",
    "for k, rec1 in enumerate(sample_tensor):\n",
    "    best = 0\n",
    "    for i in range(0,10):\n",
    "        rec2 = finetuned_tensor[k*10 + i]\n",
    "        \n",
    "        # pad\n",
    "        pad_len = np.abs(len(rec1) - len(rec2))\n",
    "        if len(rec1) < len(rec2):\n",
    "            rec1.extend([0]*pad_len)\n",
    "        else:\n",
    "            rec2.extend([0]*pad_len)\n",
    "        \n",
    "        cos = cosine_similarity([rec1], [rec2])\n",
    "        best = max(best, cos)\n",
    "    avg += best\n",
    "\n",
    "avg = avg/len(sample_tensor)\n",
    "print(\"avg: \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Language check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "#tool.disable_spellchecking()\n",
    "results = tool.check(data[\"finetuned\"][0])\n",
    "results_filtered = [result for result in results if result.ruleId!='WHITESPACE_RULE' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "#tool.disable_spellchecking()\n",
    "\n",
    "avg = 0\n",
    "dataset = \"finetuned\"\n",
    "\n",
    "for rec in tqdm(data[dataset], desc=\"Iteration\", disable=False, position=0, leave=True):\n",
    "    results = tool.check(rec)\n",
    "    results_filtered = [result for result in results if result.ruleId!='WHITESPACE_RULE' ]\n",
    "    avg += len(results_filtered)\n",
    "\n",
    "print(avg / len(data[dataset]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Readibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* textstat.smog_index(test_data)\n",
    "* textstat.flesch_kincaid_grade(test_data)\n",
    "* textstat.coleman_liau_index(test_data)\n",
    "* textstat.automated_readability_index(test_data)\n",
    "* textstat.dale_chall_readability_score(test_data)\n",
    "* textstat.difficult_words(test_data)\n",
    "* textstat.linsear_write_formula(test_data)\n",
    "* textstat.gunning_fog(test_data)\n",
    "* textstat.text_standard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import textstat\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"finetuned\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.flesch_reading_ease(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"sample\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.smog_index(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"finetuned\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.gunning_fog(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "dataset = \"sample\"\n",
    "\n",
    "for rec in data[dataset]:\n",
    "    result = textstat.dale_chall_readability_score(rec)\n",
    "    #print(result)\n",
    "    ret.append(result)\n",
    "    \n",
    "print(np.mean(ret), np.median(ret), stats.mode(ret))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.translate.bleu_score as bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import nltk.translate.gleu_score as gleu\n",
    "import nltk.translate.meteor_score as meteor\n",
    "from jiwer import wer, mer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer_count(hyp, ref, print_matrix=False):\n",
    "    N = len(hyp)\n",
    "    M = len(ref)\n",
    "    L = np.zeros((N,M))\n",
    "    for i in range(0, N):\n",
    "        for j in range(0, M):\n",
    "            if min(i,j) == 0:\n",
    "                L[i,j] = max(i,j)\n",
    "            else:\n",
    "                deletion = L[i-1,j] + 1\n",
    "                insertion = L[i,j-1] + 1\n",
    "                sub = 1 if hyp[i] != ref[j] else 0\n",
    "                substitution = L[i-1,j-1] + sub\n",
    "                L[i,j] = min(deletion, min(insertion, substitution))\n",
    "    return int(L[N-1, M-1])\n",
    "\n",
    "def bleu_score(recipe, refer):\n",
    "    hyp = recipe\n",
    "    refs = refer\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    score_ref_a = bleu.sentence_bleu(refs, hyp, smoothing_function=smoothie)\n",
    "    return score_ref_a\n",
    "\n",
    "def gleu_score(recipe, refer):\n",
    "    hyp = recipe\n",
    "    refs = refer\n",
    "    score_ref_a = gleu.sentence_gleu(refs, hyp)\n",
    "    return score_ref_a\n",
    "\n",
    "def wer_score(recipe, refer):\n",
    "    hyp = recipe\n",
    "    refs = refer\n",
    "\n",
    "    mn = 99999\n",
    "    for ref in refs:\n",
    "        b = wer(ref, hyp)\n",
    "        mn = min(mn, b)\n",
    "       \n",
    "    return mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for k, rec1 in enumerate(tqdm(data[\"sample\"])):\n",
    "    rec2 = data[\"finetuned\"][k*10: k*10 + 10]\n",
    "    res = bleu_score(rec1, rec2)\n",
    "    ret.append(res)\n",
    "\n",
    "np.mean(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for k, rec1 in enumerate(tqdm(data[\"sample\"])):\n",
    "    rec2 = data[\"finetuned\"][k*10: k*10 + 10]\n",
    "    res = gleu_score(rec1, rec2)\n",
    "    ret.append(res)\n",
    "\n",
    "np.mean(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for k, rec1 in enumerate(tqdm(data[\"sample\"])):\n",
    "    rec2 = data[\"finetuned\"][k*10: k*10 + 10]\n",
    "    res = wer_score(rec1, rec2)\n",
    "    ret.append(res)\n",
    "\n",
    "np.mean(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingredients evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if all the ingredients from the input list are used inside the generated instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_ingredients_list(recipe):\n",
    "    '''\n",
    "    Gets the list of input ingredients from a raw recipe\n",
    "    '''\n",
    "    ingr_start_index = recipe.find(\"<INPUT_START>\")\n",
    "    ingr_end_index = recipe.find(\"<INPUT_END>\")\n",
    "\n",
    "    ingredients_sequence = \" \".join(recipe[ingr_start_index + len(\"<INPUT_START>\"):ingr_end_index].strip().split())  # Find the input ingredients list sequence\n",
    "    ingredients_list = ingredients_sequence.split(\"<NEXT_INPUT>\")  # split the ingredients when the next input token is reached\n",
    "    return [x.strip() for x in ingredients_list]  # strip whitespaces before and after ingredients\n",
    "\n",
    "\n",
    "def get_instructions(recipe):\n",
    "    '''\n",
    "    Gets the string sequence of instructions from a raw recipe\n",
    "    '''\n",
    "    instr_start_index = recipe.find(\"<INSTR_START>\")\n",
    "    instr_end_index = recipe.find(\"<INSTR_END>\")\n",
    "\n",
    "    instruction_sequence = \" \".join(recipe[instr_start_index + len(\"<INSTR_START>\"):instr_end_index].strip().split())  # Find the input ingredients list sequence\n",
    "    instructions = instruction_sequence.split(\"<NEXT_INSTR>\")  # split the ingredients when the next input token is reached\n",
    "    instructions = [x.strip() for x in instructions]  # strip whitespaces before and after ingredients\n",
    "    return \" \".join(instructions)\n",
    "\n",
    "\n",
    "def input_ingredients_coverage_in_instructions(recipe):\n",
    "    '''\n",
    "    Returns the percentage of the number of ingredients from the input list that are actually present in the instructions for one recipe.\n",
    "    '''\n",
    "    ingredients = get_input_ingredients_list(recipe)\n",
    "    number_of_ingredients = len(ingredients)  # keeps the number of ingredients before removing duplicates\n",
    "    instructions = get_instructions(recipe).lower()\n",
    "\n",
    "    ingredients = list(dict.fromkeys(ingredients))  # remove duplicate ingredients to reduce bias\n",
    "    nb_ingr_found = sum([1 if ingredient.lower() in instructions else 0 for ingredient in ingredients])  # Gets the number of ingredients found in the instructions\n",
    "\n",
    "    return nb_ingr_found/number_of_ingredients\n",
    "\n",
    "\n",
    "def evaluate_recipes_input_ingredients_coverage_in_instructions(recipes):\n",
    "    '''\n",
    "    Evaluation on all the generated recipes (finetuned) for the coverage of the input list in the instructions.\n",
    "    Returns a list of percentage for the number of ingredients from the input list that are actually present in the instructions.\n",
    "    '''\n",
    "    results = []\n",
    "    for recipe in recipes:\n",
    "        results.append(input_ingredients_coverage_in_instructions(recipe))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percentage of input ingredients covered: 0.5537150981253905\n",
      "Number of 0% coverage of input ingredients: 57\n"
     ]
    }
   ],
   "source": [
    "res = evaluate_recipes_input_ingredients_coverage_in_instructions(data['finetuned'])\n",
    "print('Average percentage of input ingredients covered:', np.mean(res))\n",
    "nb_of_zeros = sum([1 if x == 0.0 else 0 for x in res])\n",
    "print('Number of 0% coverage of input ingredients:', nb_of_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONLY TESTING PURPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percentage of input ingredients covered: 0.5261598679098679\n",
      "Number of 0% coverage of input ingredients: 11\n"
     ]
    }
   ],
   "source": [
    "# Checking on the samples to see how many zeros there are, therfore checking how many \"mix, combine, there are still in the training data\".\n",
    "res = evaluate_recipes_input_ingredients_coverage_in_instructions(data['sample'])\n",
    "print('Average percentage of input ingredients covered:', np.mean(res))\n",
    "nb_of_zeros = sum([1 if x == 0.0 else 0 for x in res])\n",
    "print('Number of 0% coverage of input ingredients:', nb_of_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "15\n",
      "16\n",
      "29\n",
      "30\n",
      "39\n",
      "49\n",
      "61\n",
      "69\n",
      "73\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(res):\n",
    "    if x == 0.0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#  Apricot Rum Cream Scones Recipe   #\n",
      " ## Input ingredients ##\n",
      "`butter`\n",
      "`sugar`\n",
      "`eggs`\n",
      "`sour cream`\n",
      "`Apricot brandy`\n",
      "`Vanilla`\n",
      "`rum`\n",
      "`All-purpose`\n",
      "`Salt`\n",
      "`Baking soda`\n",
      "`Baking powder`\n",
      "`Confectioners sugar`\n",
      " ## Ingredients ##\n",
      "*  2 c. (2 sticks) butter \n",
      "*  2 c. Granulated sugar \n",
      "*  4 x Large eggs \n",
      "*  3/4 c. Lowfat sour cream \n",
      "*  1/2 c. Apricot brandy \n",
      "*  1 tsp Vanilla extract \n",
      "*  1/4 c. Rum \n",
      "*  2 c. All-purpose flour \n",
      "*  1/2 tsp Salt \n",
      "*  1 tsp Baking soda \n",
      "*  1/4 tsp Baking powder \n",
      "*  1 c. Confectioners sugar \n",
      " ## Instructions ##\n",
      "1)  Beat butter and sugar till light and fluffy. \n",
      "2)  Add in Large eggs, 1 at a time, beating well after each addition. \n",
      "3)  Sift dry ingredients and add in alternately with lowfat sour cream, beating well after each addition. \n",
      "4)  Combine apricot brandy and vanilla extract in a glass measuring c. and add in to butter mix. \n",
      "5)  Blend till smooth. \n",
      "6)  Spoon batter into a greased 10 inch tube pan and bake at 350 for 50 min. \n",
      "7)  Cold in pan 10 min. \n",
      "8)  Turn out onto rack to cold completely. \n",
      "9)  Cold completely. \n",
      "10)  With your hands, make sure you roll proportionately. \n",
      "11)  Spread scones proportionately with apricot and sugar filling. \n",
      "12)  Set on waxed paper. \n",
      "13)  Dust with confectioners sugar. \n",
      "14)  Cut in wedges. \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print_raw_recipe(data['finetuned'][16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if all the ingredients from the input list are in the ingredient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listed_ingredients_list(recipe):\n",
    "    '''\n",
    "    Gets the string sequence of listed ingredients (list with quantities) from a raw recipe\n",
    "    '''\n",
    "    ingr_start_index = recipe.find(\"<INGR_START>\")\n",
    "    ingr_end_index = recipe.find(\"<INGR_END>\")\n",
    "\n",
    "    ingredients_sequence = \" \".join(recipe[ingr_start_index + len(\"<INGR_START>\"):ingr_end_index].strip().split())  # Find the input ingredients list sequence\n",
    "    ingredients_list = ingredients_sequence.split(\"<NEXT_INGR>\")  # split the ingredients when the next input token is reached\n",
    "    ingredients_list = [x.strip() for x in ingredients_list]  # strip whitespaces before and after ingredients\n",
    "    return \" \".join(ingredients_list)\n",
    "\n",
    "\n",
    "def input_ingredients_coverage_in_listed_ingredients(recipe):\n",
    "    '''\n",
    "    Returns the percentage of the number of ingredients from the input list that are actually present in the listed ingredients (list with quantities) for one recipe.\n",
    "    '''\n",
    "    input_ingredients = get_input_ingredients_list(recipe)  # Gets input ingredients (without quantities)\n",
    "    number_of_ingredients = len(input_ingredients)  # keeps the number of ingredients before removing duplicates\n",
    "    \n",
    "    listed_ingredients = get_listed_ingredients_list(recipe).lower()  # Gets listed ingredients (the one with quanities)\n",
    "\n",
    "    ingredients = list(dict.fromkeys(input_ingredients))  # remove duplicate ingredients to reduce bias\n",
    "    nb_ingredients_found = sum([1 if input_ingredient.lower() in listed_ingredients else 0 for input_ingredient in input_ingredients])  # Gets the number of ingredients found in the listed ingredients\n",
    "    return nb_ingredients_found / number_of_ingredients\n",
    "\n",
    "\n",
    "def evaluate_recipes_input_ingredients_coverage_in_listed_ingredients(recipes):\n",
    "    '''\n",
    "    Evaluation on all the generated recipes (finetuned) for the coverage of the input list in the listed ingredients (list with quantities).\n",
    "    Returns a list of percentage for the number of ingredients from the input list that are actually present in the listed ingredients.\n",
    "    '''\n",
    "    results = []\n",
    "    for recipe in recipes:\n",
    "        results.append(input_ingredients_coverage_in_listed_ingredients(recipe))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percentage of input ingredients covered: 0.9887254493485531\n",
      "Number of non-100% coverage of input ingredients: 77\n"
     ]
    }
   ],
   "source": [
    "res = evaluate_recipes_input_ingredients_coverage_in_listed_ingredients(data['finetuned'])\n",
    "print('Average percentage of input ingredients covered:', np.mean(res))\n",
    "indx_where_not_one = [i for i, x in enumerate(res) if x != 1.0]\n",
    "print('Number of non-100% coverage of input ingredients:', len(indx_where_not_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ingredients_coverage_in_listed_ingredients(data['finetuned'][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ingredients_coverage_in_listed_ingredients(data['finetuned'][40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13,\n",
       " 40,\n",
       " 41,\n",
       " 95,\n",
       " 99,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 117,\n",
       " 118,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 237,\n",
       " 241,\n",
       " 245,\n",
       " 348,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 380,\n",
       " 463,\n",
       " 516,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 536,\n",
       " 539,\n",
       " 581,\n",
       " 586,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 686,\n",
       " 708,\n",
       " 741,\n",
       " 746,\n",
       " 749,\n",
       " 760,\n",
       " 766,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 910,\n",
       " 912,\n",
       " 913,\n",
       " 959,\n",
       " 960,\n",
       " 967]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indx_where_not_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#  Mexican Pork And Vegetable Salad   #\n",
      " ## Input ingredients ##\n",
      "`ground pork`\n",
      "`carrots`\n",
      "`onion`\n",
      "`garlic`\n",
      "`Chicken`\n",
      "`water`\n",
      "`frozen peas`\n",
      "`shredded romaine lettuce`\n",
      "`cucumber`\n",
      "`jalapeno peppers`\n",
      "`tomatoes`\n",
      "`ground cumin`\n",
      "`kosher salt`\n",
      "`freshly ground black pepper`\n",
      "`vegetable oil`\n",
      "`salsa`\n",
      " ## Ingredients ##\n",
      "*  3/4 pound ground pork \n",
      "*  2 cups peeled and chopped carrots \n",
      "*  1 cup chopped onion \n",
      "*  4 garlic cloves, minced \n",
      "*  1-1/2 cups frozen DRAINED CARROTS, thawed, drained \n",
      "*  1 cup water \n",
      "*  1 cup frozen peas \n",
      "*  1-1/4 cups shredded romaine lettuce \n",
      "*  1/2 cup chopped peeled cucumber \n",
      "*  2 tablespoons chopped pickled jalapeno peppers \n",
      "*  1 can (14-1/2 ounces) diced tomatoes, undrained \n",
      "*  1 teaspoon ground cumin \n",
      "*  3/4 teaspoon kosher salt \n",
      "*  1/2 teaspoon freshly ground black pepper \n",
      "*  2 teaspoons vegetable oil \n",
      "*  1/2 cup salsa \n",
      " ## Instructions ##\n",
      "1)  In a large skillet, cook pork, carrots, onion and garlic over medium heat until meat is no longer pink; drain. Add the carrots, water, peas, lettuce, cucumber and jalapeno peppers; bring to a boil. Reduce heat; simmer, uncovered, for 20 minutes. \n",
      "2)  In a blender, combine the tomatoes, cumin, salt and pepper; cover and process until smooth. Add oil; cover and process until blended. In a large bowl, toss with the salsa. Serve with pork mixture. \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print_raw_recipe(data['finetuned'][40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if there are any duplicates ingredients in the input list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_duplicated_input_ingredients(recipes):\n",
    "    '''\n",
    "    Returns percentage of recipes without duplicated inputs\n",
    "    '''\n",
    "    count = 0\n",
    "    for recipe in recipes:\n",
    "        ingredients = get_input_ingredients_list(recipe)\n",
    "        filtered_list = list(dict.fromkeys(ingredients))\n",
    "        if len(ingredients) == len(filtered_list):\n",
    "            count +=1\n",
    "    return count / len(recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.757"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_duplicated_input_ingredients(data['finetuned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if all the ingredients found in the generated instructions are mentioned in the input list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if all the ingredients found in the generated instructions are mentioned in the ingredients list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
