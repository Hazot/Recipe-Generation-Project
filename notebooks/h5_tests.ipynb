{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179c6f9-5f3f-4742-a73b-59d40da0cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import boto3\n",
    "import shutil\n",
    "import fire\n",
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hydra.utils import get_original_cwd\n",
    "from omegaconf import DictConfig\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3cf166-2d7d-4564-87df-4f8481e2c0e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "local_path = os.path.normpath(os.getcwd() + os.sep + os.pardir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562c4fb8-b5f9-4f7c-955d-989d79731dc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GPT2 and OPT tokenizer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8574982c-e1f5-4d99-bc82-6f8163135232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097839c-008a-45f8-9f5a-e51c9fe1fe20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenizer GPT2\n",
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2',do_lower_case=False, truncation_side='left')\n",
    "\n",
    "special_tokens = {\n",
    "    \"additional_special_tokens\": [\n",
    "        \"<TITLE_START>\",\n",
    "        \"<TITLE_END>\",\n",
    "        \"<INSTR_START>\",\n",
    "        \"<NEXT_INSTR>\",\n",
    "        \"<INSTR_END>\",\n",
    "        \"<INGR_START>\",\n",
    "        \"<NEXT_INGR>\",\n",
    "        \"<INGR_END>\",\n",
    "        \"<RECIPE_START>\",\n",
    "        \"<RECIPE_END>\",\n",
    "        \"<INPUT_START>\",\n",
    "        \"<INPUT_END>\",\n",
    "        \"<NEXT_INPUT>\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "# tokenizer.pad_token_id = (\n",
    "#     0  # unk. we want this to be different from the eos token\n",
    "# )\n",
    "# tokenizer.padding_side = \"right\"  # Left: Allows batched inference, we put right for this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843f25c-18a0-4747-941c-e33e3dfe04ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_gpt2 = local_path + \"/data/unsupervised.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fe05f-59df-47de-935a-481f1bb4296b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(path_gpt2, 'r') as f:\n",
    "    data_np = f['train'][:]\n",
    "    train_dataset = torch.tensor(f['train'][:]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa3a14-0d3a-43dc-967f-6aa2946e97c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a68479-69e0-4c70-a4ee-e2cc3ed8c573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "line = train_dataloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d669b6-d14e-47f9-bf3d-309adf7d3ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9f150-2a59-4138-83b3-b6bb513914bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(line, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923c42c-15d8-46e5-a945-b4d13e00f8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenizer OPT\n",
    "model_path = local_path + \"/checkpoints/opt/checkpoint-opt-final\"\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False, do_lower_case=False, truncation_side='left')\n",
    "max_token_len = tokenizer.max_model_input_sizes[\"gpt2\"]\n",
    "\n",
    "special_tokens = {\n",
    "    \"additional_special_tokens\": [\n",
    "        \"<TITLE_START>\",\n",
    "        \"<TITLE_END>\",\n",
    "        \"<INSTR_START>\",\n",
    "        \"<NEXT_INSTR>\",\n",
    "        \"<INSTR_END>\",\n",
    "        \"<INGR_START>\",\n",
    "        \"<NEXT_INGR>\",\n",
    "        \"<INGR_END>\",\n",
    "        \"<RECIPE_START>\",\n",
    "        \"<RECIPE_END>\",\n",
    "        \"<INPUT_START>\",\n",
    "        \"<INPUT_END>\",\n",
    "        \"<NEXT_INPUT>\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4d30f-43a5-4dfc-83c1-3d07c7085091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_opt = local_path + \"/data/unsupervised_opt.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4472771f-f0e3-4666-88c2-0f99fded8b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(path_opt, 'r') as f:\n",
    "    data_np = f['train'][:]\n",
    "    train_dataset = torch.tensor(f['train'][:]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671270d3-9e27-4dcc-9a0d-42b247e399d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8badb417-ab4c-4515-bbb2-991fda5d1599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "line = train_dataloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c3d14-0beb-4a71-a90a-650a8edf38c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(line, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a89a25-609e-48d6-a79e-c556fca7cd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8fb836d-2867-465c-b6d2-91fb5f1fa3cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Llama tokenizer and h5 dataset to use huggingface Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064dee98-3604-4e4c-a510-40c3737e11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer Llama\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    'decapoda-research/llama-7b-hf',\n",
    "    do_lower_case=False,\n",
    "    truncation_side='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb1657-c963-4e1a-87ed-7e7bff9af78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {\n",
    "    \"additional_special_tokens\": [\n",
    "        \"<TITLE_START>\",\n",
    "        \"<TITLE_END>\",\n",
    "        \"<INSTR_START>\",\n",
    "        \"<NEXT_INSTR>\",\n",
    "        \"<INSTR_END>\",\n",
    "        \"<INGR_START>\",\n",
    "        \"<NEXT_INGR>\",\n",
    "        \"<INGR_END>\",\n",
    "        \"<RECIPE_START>\",\n",
    "        \"<RECIPE_END>\",\n",
    "        \"<INPUT_START>\",\n",
    "        \"<INPUT_END>\",\n",
    "        \"<NEXT_INPUT>\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "tokenizer.pad_token_id = (\n",
    "    0  # unk. we want this to be different from the eos token\n",
    ")\n",
    "tokenizer.padding_side = \"right\"  # Left: Allows batched inference, we put right for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc89801-0642-4f09-bea4-0d068929217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "path = local_path + \"/data/unsupervised_llama.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271fac6-6360-46c8-b4cd-e1bd379a574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path, 'r') as f:\n",
    "    print(f.keys())\n",
    "    raw_data = f['train']\n",
    "    train_dataset = torch.tensor(f['train'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8115da2-1678-44ea-b4db-07c312a94034",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe1a0e-0836-4b8f-934c-e45ad9d31f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba6ff3-6566-451b-9f13-3baadb604580",
   "metadata": {},
   "outputs": [],
   "source": [
    "datta = datasets.Dataset({'train':train_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55942e50-2c26-4278-a184-2f0b083c1acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = datasets.DatasetDict({'train':train_dataset}, features=['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670b07c-8e82-410f-83f1-7a21ecf0a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f15b1b2-b974-4f47-a488-e4decf999784",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_dict = {\n",
    "    'train': [train_dataset]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725f0719-574e-4b81-8088-5e94fdfc1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "px = pd.DataFrame(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e12d95-f6ce-4b4e-a7ed-863874e8f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d423e7e-3b9a-418d-848b-3edf062e4392",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dset = load_dataset(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d25311-a678-454e-ac9b-20ea950c0138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5eca9-8a29-4684-9256-dba1faaabdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5d52c-a409-4f5f-a369-dadd956e809a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c5be76-24a7-40f2-95da-b536605da84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6f3f1-1f80-412b-a3b9-b89ace2f2f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fdc7c7-45d7-41f4-b91e-f1daddb1f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf677b-4e57-4f43-b181-f3151386aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = train_dataloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f5641-cd0e-425b-ad23-acd7de3cefdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(line, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68a6eb-2b91-4952-b3c3-b3d7d86e27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd089864-692f-4b52-8a72-c27452d803d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_pandas(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768c370-3d88-4ac8-a956-4fe4bda02747",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\"train\": byte}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310cf92-f71b-4613-97d5-79fb70dd0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a8cc6-5b0d-47b3-81cb-b3167da26eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "df_train = pd.read_hdf(path)\n",
    "sentences = datasets.DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_pandas(df_train)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e7bde-070c-4b5a-9120-1a5890d0d60f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlg (3.9.16)",
   "language": "python",
   "name": "nlg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
